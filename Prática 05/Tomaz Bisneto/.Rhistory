irisP <- as.data.frame(irisP);irisP$Species <- rownames(irisP)
p <- qplot(Petal.Width,Petal.Length, col = Species, data = training)
p + geom_point(aes(x=Petal.Width, y = Petal.Length,col = col = Species),size=5, shape = 4, data = irisP)
p <- qplot(Petal.Width,Petal.Length, col = Species, data = training)
p + geom_point(aes(x=Petal.Width, y = Petal.Length, col = Species),size=5, shape = 4, data = irisP)
plot(modFit$finalModel, uniform = TRUE,main = "Árvore de Classificação")
text(modFit$finalModel,use.n = TRUE,all  = TRUE, cex=.8)
library(rattle)
fancyRpartPlot(modFit$finalModel)
data(iris); library(ggplot2)
library(caret)
names(iris)
View(iris)
table(iris$Species)
inTrain <- createDataPartition(y=iris$Species, p=0.7, list = FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training); dim(testing)
qplot(Petal.Width, Sepal.Width, colour=Species, data = training)
library(rpart)
modFit <-train(Species~.,method="rpart",data =  training)
print(modFit$finalModel)
plot(modFit$finalModel, uniform = TRUE,main = "Árvore de Classificação")
text(modFit$finalModel,use.n = TRUE,all  = TRUE, cex=.8)
library(rattle)
fancyRpartPlot(modFit$finalModel)
data(iris); library(ggplot2)
library(caret)
names(iris)
View(iris)
table(iris$Species)
inTrain <- createDataPartition(y=iris$Species, p=0.7, list = FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training); dim(testing)
getTree(modFit$finalModel,k=2)
irisP <- classCenter(training[,c(3,4)],training$Species,modFit$finalModel$prox)
irisP <- as.data.frame(irisP);irisP$Species <- rownames(irisP)
p <- qplot(Petal.Width,Petal.Length, col = Species, data = training)
p + geom_point(aes(x=Petal.Width, y = Petal.Length, col = Species),size=5, shape = 4, data = irisP)
plot(modFit$finalModel, uniform = TRUE,main = "Árvore de Classificação")
text(modFit$finalModel,use.n = TRUE,all  = TRUE, cex=.8)
library(rattle)
fancyRpartPlot(modFit$finalModel)
data(iris); library(ggplot2)
library(caret)
names(iris)
View(iris)
table(iris$Species)
inTrain <- createDataPartition(y=iris$Species, p=0.7, list = FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training); dim(testing)
getTree(modFit$finalModel,k=2)
irisP <- classCenter(training[,c(3,4)],training$Species,modFit$finalModel$prox)
irisP <- as.data.frame(irisP);irisP$Species <- rownames(irisP)
p <- qplot(Petal.Width,Petal.Length, col = Species, data = training)
p + geom_point(aes(x=Petal.Width, y = Petal.Length, col = Species),size=5, shape = 4, data = irisP)
data(iris); library(ggplot2)
library(caret)
names(iris)
View(iris)
table(iris$Species)
inTrain <- createDataPartition(y=iris$Species, p=0.7, list = FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training); dim(testing)
getTree(modFit$finalModel,k=2)
irisP <- classCenter(training[,c(3,4)],training$Species,modFit$finalModel$prox)
irisP <- as.data.frame(irisP);irisP$Species <- rownames(irisP)
p <- qplot(Petal.Width,Petal.Length, col = Species, data = training)
p + geom_point(aes(x=Petal.Width, y = Petal.Length, col = Species),size=5, shape = 4, data = irisP)
pred <- predict(modFit,testing);testing$predRight <- pred==testing$Species
table(pred,testing$Species)
confusionMatrix(pred,testing$Species)
pred <- predict(modFit,testing);testing$predRight <- pred==testing$Species
table(pred,testing$Species)
confusionMatrix(pred,testing$Species)
tabela <- data.frame(testing$Species,pred)
colnames(tabela) <- c("Valor Correto","Valor Predito")
View(tabela)
tabela <- data.frame(testing$Species,pred)
table(pred,testing$Species)
pred <- predict(modFit,testing);testing$predRight <- pred==testing$Species
table(pred,testing$Species)
confusionMatrix(pred,testing$Species)
tabela <- data.frame(testing$Species,pred)
colnames(tabela) <- c("Valor Correto","Valor Predito")
View(tabela)
qplot(Petal.Whidth,Petal.Length, colour = predRight, data = testing,main ="Classificação de Novos dados")
qplot(Petal.Width,Petal.Length, colour = predRight, data = testing,main ="Classificação de Novos dados")
View(tabela)
setwd("/home/tomaz/Documentos/R\ Teste/Tomaz\ Bisneto\ /Atividade\ 5/")
library(ggplot2)
library(caret)
#A)
#Consrtução da bases para treino e testes
dados <- read.csv("car.data",sep = ' ',header = FALSE)
View(dados)
inTrain <- createDataPartition(y=dados$V7, p=0.7, list = FALSE)
training <- dados[inTrain,]
testing <- dados[-inTrain,]
dim(training)
dim(testing)
#Gráfico de distribuição dos pontos (escolha duas variáveis para os eixos x e y, respectivamente);
qplot(V2,V6, colour=V7, data = training)
#Gráfico de distribuição dos pontos (escolha duas variáveis para os eixos x e y, respectivamente);
qplot(V1,V6, colour=V7, data = training)
#Gráfico de distribuição dos pontos (escolha duas variáveis para os eixos x e y, respectivamente);
qplot(V3,V6, colour=V7, data = training)
#Gráfico de distribuição dos pontos (escolha duas variáveis para os eixos x e y, respectivamente);
qplot(V2,V6, colour=V7, data = training)
modFit <- train(V7~., data = training, method = "rf", prox = TRUE)
modFit
getTree(modFit$finalModel, k = 2)
data(iris)
library(ggplot2)
library(caret)
names(iris)
summary(iris)
str(iris)
table(iris$Species)
inTrain <- createDataPartition(y = iris$Species, p = 0.7, list = FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training)
dim(testing)
modFit <- train(Species ~., data = training, method = "rf", prox = TRUE)
modFit
getTree(modFit$finalModel, k = 2)
irisP <- classCenter(training[,c(3,4)], training$Species, modFit$finalModel$prox)
irisP <- as.data.frame(irisP)
irisP$Species <-rownames(irisP)
p <- qplot(Petal.Width, Petal.Length, col = Species, data = training)
p + geom_point(aes(x = Petal.Width, y = Petal.Length
, col = Species), size = 5, shape = 4, data = irisP)
setwd("/home/tomaz/Documentos/R\ Teste/Tomaz\ Bisneto\ /Atividade\ 5/")
library(ggplot2)
library(caret)
#A)
#Consrtução da bases para treino e testes
dados <- read.csv("car.data",sep = ' ',header = FALSE)
View(dados)
inTrain <- createDataPartition(y=dados$V7, p=0.7, list = FALSE)
training <- dados[inTrain,]
testing <- dados[-inTrain,]
dim(training)
dim(testing)
qplot(V2,V6, colour=V7, data = training)
modFit <- train(V7~., data = training, method = "rf", prox = TRUE)
modFit
getTree(modFit$finalModel, k = 2)
# Visualização gráfica da árvore montada;
plot(modFit$finalModel, uniform = TRUE,main = "Árvore de Classificação")
text(modFit$finalModel,use.n = TRUE,all  = TRUE, cex=.8)
library(rattle)
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit$finalModel)
plot(modFit$finalModel, uniform = TRUE,main = "Árvore de Classificação")
text(modFit$finalModel,use.n = TRUE,all  = TRUE, cex=.8)
modFit <- train(V7~., data = training, method = "rf", prox = TRUE)
modFit
getTree(modFit$finalModel, k = 2)
# Visualização gráfica da árvore montada;
plot(modFit$finalModel, uniform = TRUE,main = "Árvore de Classificação")
text(modFit$finalModel,use.n = TRUE,all  = TRUE, cex=.8)
library(rattle)
fancyRpartPlot(modFit$finalModel)
dev.off()
dev.off()
plot(modFit$finalModel, uniform = TRUE,main = "Árvore de Classificação")
text(modFit$finalModel,use.n = TRUE,all  = TRUE, cex=.8)
plot(modFit$finalModel, uniform = TRUE,main = "Árvore de Classificação")
dev.off()
plot(modFit$finalModel, uniform = TRUE,main = "Árvore de Classificação")
text(modFit$finalModel,use.n = TRUE,all  = TRUE, cex=.8)
library(rattle)
fancyRpartPlot(modFit$finalModel)
dev.off()
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit)
library(rattle)
fancyRpartPlot(modFit$finalModel)
qplot(Petal.Width, Petal.Length, colour = predRight, data = testing,
main = "Classificação de novos dados")
data(iris)
library(ggplot2)
library(caret)
names(iris)
summary(iris)
str(iris)
table(iris$Species)
inTrain <- createDataPartition(y = iris$Species, p = 0.7, list = FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training)
dim(testing)
modFit <- train(Species ~., data = training, method = "rf", prox = TRUE)
modFit
getTree(modFit$finalModel, k = 2)
irisP <- classCenter(training[,c(3,4)], training$Species, modFit$finalModel$prox)
irisP <- as.data.frame(irisP)
irisP$Species <-rownames(irisP)
p <- qplot(Petal.Width, Petal.Length, col = Species, data = training)
p + geom_point(aes(x = Petal.Width, y = Petal.Length
, col = Species), size = 5, shape = 4, data = irisP)
#dev.off()
pred <- predict(modFit, testing)
testing$predRight <- pred == testing$Species
table(pred, testing$Species)
confusionMatrix(pred, testing$Species)
tabela <- data.frame(testing$Species, pred)
colnames(tabela) <- c("Valor correto", "Valor predito")
View(tabela)
qplot(Petal.Width, Petal.Length, colour = predRight, data = testing,
main = "Classificação de novos dados")
#Matriz de Confuzão
p <- predict(modFit,newdata = testing)
confusionMatrix(p,testing$V7)
table(p,testing$V7)
setwd("/home/tomaz/Documentos/R\ Teste/Tomaz\ Bisneto\ /Atividade\ 5/")
library(ggplot2)
library(caret)
#A)
#Consrtução da bases para treino e testes
dados <- read.csv("car.data",sep = ' ',header = FALSE)
View(dados)
inTrain <- createDataPartition(y=dados$V7, p=0.7, list = FALSE)
training <- dados[inTrain,]
testing <- dados[-inTrain,]
dim(training)
dim(testing)
#Gráfico de distribuição dos pontos (escolha duas variáveis para os eixos x e y, respectivamente);
qplot(V2,V6, colour=V7, data = training)
modFit <- train(V7~., data = training, method = "rf", prox = TRUE)
modFit
getTree(modFit$finalModel, k = 2)
#dev.off()
# Visualização gráfica da árvore montada;
plot(modFit$finalModel, uniform = TRUE,main = "Árvore de Classificação")
text(modFit$finalModel,use.n = TRUE,all  = TRUE, cex=.8)
library(rattle)
fancyRpartPlot(modFit$finalModel)
#Matriz de Confuzão
p <- predict(modFit,newdata = testing)
confusionMatrix(p,testing$V7)
table(p,testing$V7)
# Monte um dataframe contendo as saidas do conjunto de teste e as saídas obtidas pelo modelo preditivo para as mesmas saídas;
tabela <- data.frame(testing$V7,p)
colnames(tabela) <- c("Valor Correto","Valor Predito")
View(tabela)
ctrl <- trainControl(method = "cv", number = 10)
fit <- train(V7~ ., data = dados ,method = "rf",trControl = ctrl)
fancyRpartPlot(fit$finalModel)
pedit <- predict(modFit,newdata = testing)
confusionMatrix(pedit,testing$V7)
table(pedit,testing$V7)
ctrl <- trainControl(method = "cv", number = 10)
fit <- train(V7~ ., data = dados ,method = "rpart",trControl = ctrl)
fancyRpartPlot(fit$finalModel)
pedit <- predict(modFit,newdata = testing)
ctrl <- trainControl(method = "cv", number = 10)
fit <- train(V7~ ., data = dados ,method = "rf",trControl = ctrl)
fancyRpartPlot(fit$finalModel)
pedit <- predict(modFit,newdata = testing)
confusionMatrix(pedit,testing$V7)
table(pedit,testing$V7)
fancyRpartPlot
fancyRpartPlot(fit$finalModel)
fancyRfPlot(fit$finalModel)
ctrl <- trainControl(method = "cv", number = 10)
fit <- train(V7~ ., data = dados ,method = "rf",trControl = ctrl)
pedit <- predict(modFit,newdata = testing)
confusionMatrix(pedit,testing$V7)
table(pedit,testing$V7)
fit
ctrl <- trainControl(method = "cv", number = 10)
fit <- train(V7~ ., data = dados ,method = "rf",trControl = ctrl)
pedit <- predict(fit,newdata = testing)
ctrl <- trainControl(method = "cv", number = 10)
fit <- train(V7~ ., data = dados ,method = "rf",trControl = ctrl)
pedit <- predict(fit,newdata = testing)
confusionMatrix(pedit,testing$V7)
table(pedit,testing$V7)
setwd("/home/tomaz/Documentos/R\ Teste/Tomaz\ Bisneto\ /Atividade\ 5/")
library(ggplot2)
library(caret)
#A)
#Consrtução da bases para treino e testes
dados <- read.csv("car.data",sep = ' ',header = FALSE)
View(dados)
inTrain <- createDataPartition(y=dados$V7, p=0.7, list = FALSE)
training <- dados[inTrain,]
testing <- dados[-inTrain,]
dim(training)
dim(testing)
#Gráfico de distribuição dos pontos (escolha duas variáveis para os eixos x e y, respectivamente);
qplot(V2,V6, colour=V7, data = training)
#Treinamento do modelo
library(rpart)
modFit <-train(V7~.,method="rpart",data =  training)
print(modFit$finalModel)
# Visualização gráfica da árvore montada;
plot(modFit$finalModel, uniform = TRUE,main = "Árvore de Classificação")
text(modFit$finalModel,use.n = TRUE,all  = TRUE, cex=.8)
library(rattle)
fancyRpartPlot(modFit$finalModel)
#Matriz de Confuzão
p <- predict(modFit,newdata = testing)
confusionMatrix(p,testing$V7)
table(p,testing$V7)
#Faça análises sobre a matriz de confusão, acurácia, índice Kappa, e os níveis de sensibilidade e especificidade de cada classe (pode ser em forma de comentário no código).
# - - -- -  -- -- - - -#
#Durante os testes, os resultados obitidos para matriz de confuzão foi AB=54 corretos e 9 incorretos ja para NO=22 e 9 inforretos.O modelo teve
#uma acuracia de 81% nos resultados, que para alguns modelos de classificação pode ser classificado como moderado os resultados. Ao analisar o
#indice capa dessse modelo verificamos que a concordancia do mesmo é de 0.61, sujerindo, a partir de referencias estatisticas, que o modelo possui
#substancial aceitação, possibilitando um bom novel de concordancia de resultados.Tambem podemos retirar da matriz dois iportantes valores que são os
#valores de sensibilidade e especificidade, que nos resultados do modelo foram, respectivamente, 0.8571 e 0.7333, demostrando que esses valore
#são condisentes ao valor da acuracia, representando que o modelo tem uma qualidade de aceitação moderada. Por fim, um ultimo valor apresetado na
#matriz que esta referindo a resultado da acuracia para dados não balanceados(Balanced Accuracy) o modelo utilisado apresenta resultado de 0.7952.
#------- - - - - -- - -#
# Monte um dataframe contendo as saidas do conjunto de teste e as saídas obtidas pelo modelo preditivo para as mesmas saídas;
tabela <- data.frame(testing$V7,p)
colnames(tabela) <- c("Valor Correto","Valor Predito")
View(tabela)
#B)
#Novo Modelo de Treinamento com Cross Validation
ctrl <- trainControl(method = "cv", number = 10)
fit <- train(V7~ ., data = dados ,method = "rpart",trControl = ctrl)
fancyRpartPlot(fit$finalModel)
pedit <- predict(fit,newdata = testing)
confusionMatrix(pedit,testing$V7)
table(pedit,testing$V7)
#Faça análises sobre a matriz de confusão, acurácia, índice Kappa, e os níveis de sensibilidade e especificidade de cada classe (pode ser em forma de comentário no código).
# - - -- -  -- -- - - -#
#Durante os testes, os resultados obitidos para matriz de confuzão foi AB=54 corretos e 9 incorretos ja para NO=22 e 9 inforretos.O modelo teve
#uma acuracia de 81% nos resultados, que para alguns modelos de classificação pode ser classificado como moderado os resultados. Ao analisar o
#indice capa dessse modelo verificamos que a concordancia do mesmo é de 0.61, sujerindo, a partir de referencias estatisticas, que o modelo possui
#substancial aceitação, possibilitando um bom novel de concordancia de resultados.Tambem podemos retirar da matriz dois iportantes valores que são os
#valores de sensibilidade e especificidade, que nos resultados do modelo foram, respectivamente, 0.8571 e 0.7333, demostrando que esses valore
#são condisentes ao valor da acuracia, representando que o modelo tem uma qualidade de aceitação moderada. Por fim, um ultimo valor apresetado na
#matriz que esta referindo a resultado da acuracia para dados não balanceados(Balanced Accuracy) o modelo utilisado apresenta resultado de 0.7952.
setwd("/home/tomaz/Documentos/R\ Teste/Tomaz\ Bisneto\ /Atividade\ 5/")
library(ggplot2)
library(caret)
#A)
#Consrtução da bases para treino e testes
dados <- read.csv("car.data",sep = ' ',header = FALSE)
View(dados)
inTrain <- createDataPartition(y=dados$V7, p=0.7, list = FALSE)
training <- dados[inTrain,]
testing <- dados[-inTrain,]
dim(training)
dim(testing)
#Gráfico de distribuição dos pontos (escolha duas variáveis para os eixos x e y, respectivamente);
qplot(V2,V6, colour=V7, data = training)
modFit <- train(V7~., data = training, method = "rf", prox = TRUE)
modFit
getTree(modFit$finalModel, k = 2)
#dev.off()
# Visualização gráfica da árvore montada;
plot(modFit$finalModel, uniform = TRUE,main = "Árvore de Classificação")
text(modFit$finalModel,use.n = TRUE,all  = TRUE, cex=.8)
library(rattle)
fancyRpartPlot(modFit$finalModel)
#Matriz de Confuzão
p <- predict(modFit,newdata = testing)
confusionMatrix(p,testing$V7)
table(p,testing$V7)
#Faça análises sobre a matriz de confusão, acurácia, índice Kappa, e os níveis de sensibilidade e especificidade de cada classe (pode ser em forma de comentário no código).
# - - -- -  -- -- - - -#
#Durante os testes, os resultados obitidos para matriz de confuzão foi AB=55 corretos e 8 incorretos ja para NO=26 e 4 inforretos.O modelo teve
#uma acuracia de 87% nos resultados, que para alguns modelos de classificação pode ser classificado como moderado os resultados. Ao analisar o
#indice capa dessse modelo verificamos que a concordancia do mesmo é de 0.71, sujerindo, a partir de referencias estatisticas, que o modelo possui
#substancial aceitação, possibilitando um bom novel de concordancia de resultados.Tambem podemos retirar da matriz dois iportantes valores que são os
#valores de sensibilidade e especificidade, que nos resultados do modelo foram, respectivamente,0.8730 e 0.8667 , demostrando que esses valore
#são condisentes ao valor da acuracia, representando que o modelo tem uma qualidade de aceitação moderada. Por fim, um ultimo valor apresetado na
#matriz que esta referindo a resultado da acuracia para dados não balanceados(Balanced Accuracy) o modelo utilisado apresenta resultado de  0.8698.
#------- - - - - -- - -#
# Monte um dataframe contendo as saidas do conjunto de teste e as saídas obtidas pelo modelo preditivo para as mesmas saídas;
tabela <- data.frame(testing$V7,p)
colnames(tabela) <- c("Valor Correto","Valor Predito")
View(tabela)
#B)
#Novo Modelo de Treinamento com Cross Validation
ctrl <- trainControl(method = "cv", number = 10)
fit <- train(V7~ ., data = dados ,method = "rf",trControl = ctrl)
pedit <- predict(fit,newdata = testing)
confusionMatrix(pedit,testing$V7)
table(pedit,testing$V7)
# - - -- -  -- -- - - -#
#Durante os testes, os resultados obitidos para matriz de confuzão foi AB=55 corretos e 8 incorretos ja para NO=26 e 4 inforretos.O modelo teve
#uma acuracia de 87% nos resultados, que para alguns modelos de classificação pode ser classificado como moderado os resultados. Ao analisar o
#indice capa dessse modelo verificamos que a concordancia do mesmo é de 0.71, sujerindo, a partir de referencias estatisticas, que o modelo possui
#substancial aceitação, possibilitando um bom novel de concordancia de resultados.Tambem podemos retirar da matriz dois iportantes valores que são os
#valores de sensibilidade e especificidade, que nos resultados do modelo foram, respectivamente,0.8730 e 0.8667 , demostrando que esses valore
#são condisentes ao valor da acuracia, representando que o modelo tem uma qualidade de aceitação moderada. Por fim, um ultimo valor apresetado na
#matriz que esta referindo a resultado da acuracia para dados não balanceados(Balanced Accuracy) o modelo utilisado apresenta resultado de  0.8698.
#------- - - - - -- - -#
setwd("/home/tomaz/Documentos/R\ Teste/Tomaz\ Bisneto\ /Atividade\ 5/")
library(ggplot2)
library(caret)
#A)
#Consrtução da bases para treino e testes
dados <- read.csv("car.data",sep = ' ',header = FALSE)
View(dados)
inTrain <- createDataPartition(y=dados$V7, p=0.7, list = FALSE)
training <- dados[inTrain,]
testing <- dados[-inTrain,]
dim(training)
dim(testing)
#Gráfico de distribuição dos pontos (escolha duas variáveis para os eixos x e y, respectivamente);
qplot(V2,V6, colour=V7, data = training)
#Treinamento do modelo
library(rpart)
modFit <-train(V7~.,method="rpart",data =  training)
print(modFit$finalModel)
# Visualização gráfica da árvore montada;
plot(modFit$finalModel, uniform = TRUE,main = "Árvore de Classificação")
text(modFit$finalModel,use.n = TRUE,all  = TRUE, cex=.8)
library(rattle)
fancyRpartPlot(modFit$finalModel)
#Matriz de Confuzão
p <- predict(modFit,newdata = testing)
confusionMatrix(p,testing$V7)
table(p,testing$V7)
#Faça análises sobre a matriz de confusão, acurácia, índice Kappa, e os níveis de sensibilidade e especificidade de cada classe (pode ser em forma de comentário no código).
# - - -- -  -- -- - - -#
#Durante os testes, os resultados obitidos para matriz de confuzão foi AB=54 corretos e 9 incorretos ja para NO=22 e 8 inforretos.O modelo teve
#uma acuracia de 81% nos resultados, que para alguns modelos de classificação pode ser classificado como moderado os resultados. Ao analisar o
#indice capa dessse modelo verificamos que a concordancia do mesmo é de 0.61, sujerindo, a partir de referencias estatisticas, que o modelo possui
#substancial aceitação, possibilitando um bom novel de concordancia de resultados.Tambem podemos retirar da matriz dois iportantes valores que são os
#valores de sensibilidade e especificidade, que nos resultados do modelo foram, respectivamente, 0.8571 e 0.7333, demostrando que esses valore
#são condisentes ao valor da acuracia, representando que o modelo tem uma qualidade de aceitação moderada. Por fim, um ultimo valor apresetado na
#matriz que esta referindo a resultado da acuracia para dados não balanceados(Balanced Accuracy) o modelo utilisado apresenta resultado de 0.7952.
#------- - - - - -- - -#
# Monte um dataframe contendo as saidas do conjunto de teste e as saídas obtidas pelo modelo preditivo para as mesmas saídas;
tabela <- data.frame(testing$V7,p)
colnames(tabela) <- c("Valor Correto","Valor Predito")
View(tabela)
#B)
#Novo Modelo de Treinamento com Cross Validation
ctrl <- trainControl(method = "cv", number = 10)
fit <- train(V7~ ., data = dados ,method = "rpart",trControl = ctrl)
fancyRpartPlot(fit$finalModel)
pedit <- predict(fit,newdata = testing)
confusionMatrix(pedit,testing$V7)
table(pedit,testing$V7)
#Faça análises sobre a matriz de confusão, acurácia, índice Kappa, e os níveis de sensibilidade e especificidade de cada classe (pode ser em forma de comentário no código).
# - - -- -  -- -- - - -#
#Durante os testes, os resultados obitidos para matriz de confuzão foi AB=54 corretos e 9 incorretos ja para NO=22 e 8 inforretos.O modelo teve
#uma acuracia de 82% nos resultados, que para alguns modelos de classificação pode ser classificado como moderado os resultados. Ao analisar o
#indice capa dessse modelo verificamos que a concordancia do mesmo é de 0.61, sujerindo, a partir de referencias estatisticas, que o modelo possui
#substancial aceitação, possibilitando um bom novel de concordancia de resultados.Tambem podemos retirar da matriz dois iportantes valores que são os
#valores de sensibilidade e especificidade, que nos resultados do modelo foram, respectivamente, 0.8571 e 0.7333, demostrando que esses valore
#são condisentes ao valor da acuracia, representando que o modelo tem uma qualidade de aceitação moderada. Por fim, um ultimo valor apresetado na
#matriz que esta referindo a resultado da acuracia para dados não balanceados(Balanced Accuracy) o modelo utilisado apresenta resultado de 0.7952.
#------- - - - - -- - -#
setwd("/home/tomaz/Documentos/R\ Teste/Tomaz\ Bisneto\ /Atividade\ 5/")
library(ggplot2)
library(caret)
#A)
#Consrtução da bases para treino e testes
dados <- read.csv("car.data",sep = ' ',header = FALSE)
View(dados)
inTrain <- createDataPartition(y=dados$V7, p=0.7, list = FALSE)
training <- dados[inTrain,]
testing <- dados[-inTrain,]
dim(training)
dim(testing)
#Gráfico de distribuição dos pontos (escolha duas variáveis para os eixos x e y, respectivamente);
qplot(V2,V6, colour=V7, data = training)
modFit <- train(V7~., data = training, method = "rf", prox = TRUE)
modFit
getTree(modFit$finalModel, k = 2)
#dev.off()
# Visualização gráfica da árvore montada;
plot(modFit$finalModel, uniform = TRUE,main = "Árvore de Classificação")
text(modFit$finalModel,use.n = TRUE,all  = TRUE, cex=.8)
library(rattle)
fancyRpartPlot(modFit$finalModel)
#Matriz de Confuzão
p <- predict(modFit,newdata = testing)
confusionMatrix(p,testing$V7)
table(p,testing$V7)
#Faça análises sobre a matriz de confusão, acurácia, índice Kappa, e os níveis de sensibilidade e especificidade de cada classe (pode ser em forma de comentário no código).
# - - -- -  -- -- - - -#
#Durante os testes, os resultados obitidos para matriz de confuzão foi AB=55 corretos e 8 incorretos ja para NO=26 e 4 inforretos.O modelo teve
#uma acuracia de 87% nos resultados, que para alguns modelos de classificação pode ser classificado como moderado os resultados. Ao analisar o
#indice capa dessse modelo verificamos que a concordancia do mesmo é de 0.71, sujerindo, a partir de referencias estatisticas, que o modelo possui
#substancial aceitação, possibilitando um bom novel de concordancia de resultados.Tambem podemos retirar da matriz dois iportantes valores que são os
#valores de sensibilidade e especificidade, que nos resultados do modelo foram, respectivamente,0.8730 e 0.8667 , demostrando que esses valore
#são condisentes ao valor da acuracia, representando que o modelo tem uma qualidade de aceitação moderada. Por fim, um ultimo valor apresetado na
#matriz que esta referindo a resultado da acuracia para dados não balanceados(Balanced Accuracy) o modelo utilisado apresenta resultado de  0.8698.
#------- - - - - -- - -#
# Monte um dataframe contendo as saidas do conjunto de teste e as saídas obtidas pelo modelo preditivo para as mesmas saídas;
tabela <- data.frame(testing$V7,p)
colnames(tabela) <- c("Valor Correto","Valor Predito")
View(tabela)
#B)
#Novo Modelo de Treinamento com Cross Validation
ctrl <- trainControl(method = "cv", number = 10)
fit <- train(V7~ ., data = dados ,method = "rf",trControl = ctrl)
pedit <- predict(fit,newdata = testing)
confusionMatrix(pedit,testing$V7)
table(pedit,testing$V7)
# - - -- -  -- -- - - -#
ctrl <- trainControl(method = "cv", number = 10)
fit <- train(V7~ ., data = training ,method = "rf",trControl = ctrl)
pedit <- predict(fit,newdata = testing)
confusionMatrix(pedit,testing$V7)
table(pedit,testing$V7)
